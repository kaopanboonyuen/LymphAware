# ğŸ§¬ LymphAware: Domain-Aware Bias Disruption for Reliable Lymphoma Cancer AI Diagnosis

<div align="center">

<b>Teerapong Panboonyuen</b><br/>
College of Computing, Khon Kaen University<br/>
ğŸ“ Supported by the <b>Talent Scholarship for Exceptional Ability</b><br/><br/>

<b>Peer-Reviewed & Accepted at IEEE Access (February 2026)</b> ğŸ‰<br/>
DOI: 10.1109/ACCESS.2026.3667575

</div>

---

<p align="center">
  <img src="images/main_01.png" width="95%" alt="LymphAware Architecture"/>
</p>

## ğŸš€ Overview

**LymphAware** is a domain-aware bias disruption framework designed to improve the **reliability, robustness, and clinical relevance** of AI systems for lymphoma histopathology diagnosis.

Modern medical AI models often achieve high accuracy by exploiting **non-biological shortcuts** â€” such as stain color, scanner signatures, or slide artifacts â€” instead of true pathological morphology. While effective in-domain, these shortcuts lead to **fragile performance under cross-center variability**, which is unacceptable for clinical deployment.

LymphAware explicitly addresses this challenge by **separating morphology-relevant signals from shortcut-driven acquisition factors**, enabling models to â€œthink more like pathologists.â€ ğŸ§ ğŸ”¬

---

## âœ¨ Key Innovations

ğŸ”¹ **Tri-Path Morphology Purification Architecture**

* Morphology-centric feature encoder
* Shortcut identification & suppression branch
* Cross-domain stability alignment stream

ğŸ”¹ **Artifact-Shift Counterfactual Training**

* Simulated staining and scanner perturbations
* Exposure of latent shortcut dependencies
* Acquisition-invariant representation learning

ğŸ”¹ **Domain-Aware Robustness Without Explicit Labels**

* Works under realistic multi-source settings
* No assumption of verified institutional separation

---

## ğŸ“Š Qualitative Results â€” Shortcut Suppression

<p align="center">
  <img src="images/main_02.png" width="95%" alt="Qualitative Results"/>
</p>

Models trained **without** LymphAware rely heavily on stain tone, background artifacts, and acquisition noise.
With LymphAware, attention shifts toward **diagnostically meaningful lymphoid morphology**.

---

## ğŸ“ˆ Cross-Center Performance

<p align="center">
  <img src="images/main_03.png" width="95%" alt="Performance Tables"/>
</p>

Across five independent medical centers:

âœ… Higher AUC
âœ… Lower false positive rates
âœ… Reduced variance across backbones
âœ… Stronger causal consistency metrics

---

## ğŸ† Acceptance Evidence

<p align="center">
  <img src="images/main_04.png" width="95%" alt="IEEE Acceptance"/>
</p>

This work has been **peer-reviewed and accepted** for publication in *IEEE Access*, highlighting its contribution to reliable medical AI research.

---

## ğŸ“– Official Publication & Citation

<div align="center">

ğŸ”— **Read the official IEEE publication:**
[https://ieeexplore.ieee.org/document/11408775](https://ieeexplore.ieee.org/document/11408775)

ğŸ“Œ **DOI:** 10.1109/ACCESS.2026.3667575

Published in *IEEE Access*, Early Access, February 2026.

</div>

---

## ğŸ§  Why LymphAware Matters

Medical AI systems must be:

* âœ” Robust across scanners and hospitals
* âœ” Grounded in biological morphology
* âœ” Clinically interpretable
* âœ” Stable under domain shift

LymphAware moves the field closer to **trustworthy computational pathology** by addressing shortcut bias at the **representation level**, rather than relying solely on dataset curation or domain labels.

---

## ğŸš€ Training LymphAware

We provide a **clean, reproducible PyTorch pipeline** located in the `src/` directory for training LymphAware across multi-center lymphoma datasets.

The framework is **backbone-agnostic** and supports:

* ğŸ§  ResNet (18 / 50 / 152)
* ğŸŒ¿ DenseNet (121)
* ğŸ”­ Vision Transformers (ViT-L/16)
* ğŸ¥ Multi-center domain training (Centers Aâ€“E)
* ğŸ¨ Artifact-shift augmentation for shortcut exposure
* ğŸ“ˆ AUC and FPR evaluation

---

### ğŸ“‚ Project Structure

```
LymphAware/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_lymphaware.py
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ losses/
â”‚   â””â”€â”€ utils/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ CenterA/
â”‚   â”œâ”€â”€ CenterB/
â”‚   â”œâ”€â”€ CenterC/
â”‚   â”œâ”€â”€ CenterD/
â”‚   â””â”€â”€ CenterE/
â”‚
â””â”€â”€ outputs/
```

Each center directory should contain class folders:

```
CenterA/
    CLL/
    FL/
    MCL/
```

---

### âš™ï¸ Installation

```bash
git clone https://github.com/kaopanboonyuen/LymphAware.git
cd LymphAware

conda create -n lymphaware python=3.10
conda activate lymphaware

pip install -r requirements.txt
```

---

### â–¶ï¸ Training Example

Train on a specific center (e.g., Center A):

```bash
python src/train_lymphaware.py \
    --train_dir data/CenterA/train \
    --val_dir data/CenterA/test \
    --backbone resnet50 \
    --epochs 100 \
    --batch_size 16 \
    --lr 3e-4
```

---

### ğŸ”¬ Training with Vision Transformer (Best Performance)

```bash
python src/train_lymphaware.py \
    --train_dir data/CenterA/train \
    --val_dir data/CenterA/test \
    --backbone vit_large_patch16_224 \
    --epochs 100
```

---

### ğŸ’¾ Outputs

Training artifacts will be saved to:

```
outputs/
    best_model.pth
```

The script automatically:

âœ… Tracks validation AUC
âœ… Computes False Positive Rate (FPR)
âœ… Saves the best checkpoint
âœ… Supports GPU acceleration

---

### ğŸ§ª Multi-Center Reproduction (Centers Aâ€“E)

To reproduce the paper results:

1. Train a model per center
2. Evaluate cross-domain performance
3. Average metrics across runs

Example loop:

```bash
for CENTER in CenterA CenterB CenterC CenterD CenterE
do
  python src/train_lymphaware.py \
      --train_dir data/${CENTER}/train \
      --val_dir data/${CENTER}/test \
      --backbone vit_large_patch16_224
done
```

---

### â­ Research Tips (From the Paper)

For best performance reported in IEEE Access:

* Backbone: **ViT-L/16**
* Epochs: **100**
* Optimizer: **AdamW**
* Learning rate: **3e-4**
* Image size: **224 Ã— 224**
* Loss weight (orthogonality): **0.1**

---

### ğŸ§  Why This Training Matters

Unlike standard pipelines, LymphAware training:

* Disrupts shortcut bias during representation learning
* Encourages morphology-grounded predictions
* Improves robustness across scanners and institutions
* Produces clinically meaningful attribution behavior

> **The model learns cancer morphology â€” not acquisition artifacts.**

---

If you find this work useful, please â­ star the repository.

---

## ğŸ™ Acknowledgement

This research is supported by:

ğŸ“ Talent Scholarship for Exceptional Ability
ğŸ« College of Computing, Khon Kaen University

---

## ğŸŒŸ Final Note

> **LymphAware learns the cancer â€” not the confounders.**

By enforcing morphology-grounded representations and suppressing shortcut bias, we aim to build AI systems that clinicians can truly trust.

---

â­ If you find this project useful, please consider starring the repository!

---

### ğŸ“š BibTeX Citation

```bibtex
@article{panboonyuen2026lymphaware,
  author    = {Teerapong Panboonyuen},
  title     = {LymphAware: Domain-Aware Bias Disruption for Reliable Lymphoma Cancer AI Diagnosis},
  journal   = {IEEE Access},
  year      = {2026},
  pages     = {1--1},
  doi       = {10.1109/ACCESS.2026.3667575},
  publisher = {IEEE}
}
```

If you use this work in your research, please cite the official IEEE version via the DOI above.

---